# Mini Search Engine - Interview Q&A Guide
**Project:** Mini Search Engine | C++, Data Structures  
**Resume Description:** Developed a text-based search engine in C++ leveraging maps and vectors for efficient storage and retrieval of problem statements. Integrated regular expressions to implement robust filtering and pattern matching for accurate and fast query processing. Optimized performance using STL containers to handle large datasets, ensuring scalable and dynamic search operations.

--- 

## üß† Project Understanding

### 1. What is your mini search engine project about?
It's a C++-based search engine that searches through a database of 455 DSA problems from Striver's A2Z sheet. It takes user queries, tokenizes them, and returns relevant problem statements with their solution URLs ranked by relevance.

### 2. What problem does it solve?
It helps developers quickly find specific DSA problems without manually scrolling through hundreds of entries. It supports multi-word queries and ranks results by how many search terms match each problem.

### 3. What kind of data are you searching?
I'm searching through structured text data - specifically problem statements (titles and descriptions) and their corresponding solution URLs. Each entry has a line number, problem text, and associated GeeksforGeeks URL.

### 4. How does your search engine work end to end?
1. User enters a query (e.g., "binary search tree")
2. Query is tokenized into individual words
3. Each word is searched using regex pattern matching across all problem statements
4. Results are collected in vectors and ranked by match count
5. Top results with URLs are returned to the user

### 5. What's the input and output format?
**Input:** Command-line string argument or web API query  
**Output:** Formatted string with match score, line number, problem text, and solution URL - or multiple ranked results separated by match scores.

### 6. How is the data stored internally?
I use two `map<int, string>` containers:
- `getFileToMap`: Maps line numbers to problem statements
- `getUrlForSolution`: Maps line numbers to solution URLs
This allows O(log n) access time and maintains sorted order by line number.

### 7. How do you process a user's query?
I tokenize the query using `stringstream`, store words in an array, then search each word independently using regex. Each word's matches are stored in separate `vector<int>` arrays indexed by word position.

### 8. How do you handle case sensitivity?
I use `regex_constants::icase` flag in my regex constructor, making all searches case-insensitive. This ensures "Array", "array", and "ARRAY" all match.

### 9. How do you deal with duplicate entries?
I use a `map<int, int>` called `lineMatchCounts` that tracks how many search words match each line. This naturally handles duplicates and provides a relevance score for ranking.

### 10. What's the time complexity of your search operation?
**Overall:** O(N * M * W) where N = number of lines, M = average line length, W = number of search words  
**Breakdown:**
- File loading: O(N) - done once
- Regex search per word: O(N * M)
- Result ranking: O(K log K) where K = matched lines
- Map operations: O(log N) per access

---

## ‚öôÔ∏è C++ & Data Structures

### 11. Why did you use map and vector?
**Map:** Ordered storage with O(log n) access, maintains line number ordering, and provides range-based operations.  
**Vector:** Dynamic arrays for storing match indices - O(1) append, cache-friendly, and supports efficient sorting.

### 12. Why not unordered_map?
I needed ordered traversal by line numbers for consistent results. Also, with only 455 entries, the O(log n) vs O(1) difference is negligible, but ordered access matters for user experience.

### 13. Difference between map and unordered_map.
**Map:** Red-black tree, O(log n) operations, ordered, more memory overhead  
**Unordered_map:** Hash table, O(1) average operations, unordered, better for large datasets where order doesn't matter

### 14. How does a map store data internally?
It uses a self-balancing Red-Black Tree. Each node stores a key-value pair, with left subtree having smaller keys and right having larger. Balancing ensures O(log n) operations.

### 15. What's the average and worst-case complexity for search in a map?
**Average & Worst:** Both O(log n) due to balanced tree structure. The self-balancing property ensures the tree height never exceeds 2*log(n+1).

### 16. Difference between vector and list.
**Vector:** Contiguous memory, O(1) random access, O(n) insertion/deletion in middle, cache-friendly  
**List:** Doubly-linked list, O(n) random access, O(1) insertion/deletion anywhere, not cache-friendly

### 17. How do you remove duplicates from a vector?
```cpp
sort(vec.begin(), vec.end());
vec.erase(unique(vec.begin(), vec.end()), vec.end());
```
First sort (O(n log n)), then `unique()` moves duplicates to end and `erase()` removes them.

### 18. How do iterators work in STL?
Iterators are pointer-like objects that traverse containers. They provide abstraction over container internals. Types include input, output, forward, bidirectional, and random-access. I use map iterators for traversing problem statements.

### 19. How do you pass vectors efficiently to functions?
By const reference to avoid copying: `void func(const vector<int>& vec)`. If modification needed, pass by reference: `void func(vector<int>& vec)`. I use this in my SearchResult vector handling.

### 20. What are pairs and how did you use them?
`std::pair` holds two heterogeneous values. I use it in `map::insert()`:
```cpp
getFileToMap.insert(std::pair<int,string>(lineNum, problemText));
```
It's useful for returning multiple values or as map keys.

---

## üîç Search Logic & Algorithm

### 21. How did you implement the search functionality?
Multi-step process:
1. Tokenize query into words
2. For each word, use regex to find all matching lines
3. Store matches in separate vectors (one per word)
4. Count how many words match each line using a map
5. Rank results by match count and return top results

### 22. Is your search linear or indexed?
It's linear - I iterate through all entries for each search. For 455 entries this is acceptable, but for larger datasets I'd implement inverted indexing where each word maps to document IDs.

### 23. How can you make it faster?
- **Inverted Index:** Pre-build word‚Üílines mapping
- **Trie:** For prefix-based search
- **Caching:** Store recent queries
- **Multithreading:** Parallel word searches
- **Database:** Use SQLite with FTS5 for large datasets

### 24. Did you consider binary search?
Not applicable for substring matching in unsorted text. Binary search works on sorted arrays for exact/range queries. My regex approach handles partial word matches and patterns better.

### 25. How would you handle prefix-based search?
Implement a Trie data structure. Each node represents a character, paths from root to nodes form words. Insert all words during initialization, then traverse from root matching query prefix - O(m) where m is prefix length.

### 26. How would you implement autocomplete?
Use Trie with frequency counts at each terminal node. As user types, traverse Trie and return top-k most frequent completions using a min-heap - O(m + k log k).

### 27. How to rank search results by relevance?
I use match count (how many query words appear in a line). Advanced: TF-IDF scoring - weighs term frequency against document frequency, prioritizing rare terms.

### 28. How do you deal with large data (like 1 lakh entries)?
- Load data in chunks/lazy loading
- Use database with indexing (SQLite/MySQL)
- Implement inverted index
- Cache frequently accessed data
- Consider memory-mapped files

### 29. How can you implement fuzzy matching (misspelled queries)?
- **Levenshtein Distance:** Calculate edit distance, accept matches within threshold
- **Phonetic Algorithms:** Soundex/Metaphone for similar-sounding words
- **N-grams:** Break words into character sequences for partial matching

### 30. What is the time complexity of your search?
**Total:** O(N * M * W + K log K)
- N = number of lines (455)
- M = average line length
- W = number of query words
- K = matched results
Regex dominates the cost at O(N * M) per word.

---

## üß© Regex & Query Processing

### 31. What is a regular expression?
A sequence of characters defining a search pattern. Used for pattern matching, validation, and text manipulation. Example: `\\b[a-z]+\\b` matches whole words.

### 32. Why did you use regex in your search engine?
For flexible pattern matching with word boundaries (`\\b`), case-insensitive search, and avoiding partial matches (e.g., "stack" shouldn't match "stackoverflow").

### 33. How does C++ implement regex?
Through `<regex>` header with ECMAScript grammar by default. Uses NFA (Non-deterministic Finite Automaton) for matching. Provides `regex_search()`, `regex_match()`, and `regex_replace()`.

### 34. What's the difference between regex_match and regex_search?
**`regex_match`:** Entire string must match the pattern (exact match)  
**`regex_search`:** Pattern can appear anywhere in string (substring match)  
I use `regex_search` to find words within problem statements.

### 35. What kind of filters did you build with regex?
Word boundary filter: `\\b` + searchWord + `\\b` ensures whole-word matching. Combined with `icase` flag for case-insensitive search. This prevents "array" from matching "arraylist".

### 36. How do you handle invalid regex patterns?
I have try-catch blocks catching `std::regex_error`:
```cpp
try {
    std::regex e("\\b" + word + "\\b", regex_constants::icase);
} catch(const std::regex_error& oor) {
    cerr << "Regex error: " << oor.code();
}
```

### 37. How does regex improve accuracy?
- Word boundaries prevent partial matches
- Case-insensitive flag catches all variations
- Special character escaping prevents syntax errors
- Pattern flexibility allows future enhancements

### 38. Can regex slow down performance?
Yes. Regex has O(n*m) complexity where n is text length and m is pattern length. Complex patterns with backtracking can be exponential. For simple exact matches, KMP or Boyer-Moore are faster.

### 39. What's the worst-case time complexity of regex search?
**Worst case:** O(2^m * n) for pathological patterns with backtracking (e.g., `(a+)+b`)  
**My case:** O(m * n) - my simple patterns avoid catastrophic backtracking  
m = pattern length, n = text length

### 40. How would you do the same without regex?
Use KMP (Knuth-Morris-Pratt) algorithm for exact string matching - O(n+m). For case-insensitive, convert both strings to lowercase first. More code but potentially faster for simple patterns.

---

## üöÄ Optimization & Scalability

### 41. What were the main performance bottlenecks?
- Regex search across all lines for each word
- File I/O on every search (now optimized with one-time loading)
- String copying in map insertions
- Multiple iterations over result sets

### 42. How did you optimize memory usage?
- Load files once, reuse maps across queries
- Use references instead of copying vectors
- Clear filter_search vectors between queries
- Avoid string concatenation in loops (use stringstream)

### 43. How did you test performance?
Used stderr debugging to log operation times, counted iterations, measured with different query sizes, and tested with large result sets (70 matches for "tree" query).

### 44. What STL features helped in optimization?
- `vector::reserve()` to preallocate space
- Move semantics (implicit in modern C++)
- `emplace_back()` instead of `push_back()` for in-place construction
- Iterator-based operations avoiding copies

### 45. How would you handle millions of entries?
- **Database with indexing:** PostgreSQL with full-text search
- **Inverted index:** Pre-compute word‚Üídocument mappings
- **Sharding:** Distribute data across multiple servers
- **Caching:** Redis for hot queries
- **Streaming:** Process results in batches

### 46. How can you parallelize the search?
Use `std::thread` or OpenMP to search different words concurrently:
```cpp
#pragma omp parallel for
for(int i=0; i<numWords; i++) {
    searchWord(words[i]);
}
```
Need mutex for shared data structures.

### 47. How do you handle dynamic additions/deletions of data?
Currently append new queries to file when no match found. For production:
- Use database with CRUD operations
- Implement transaction logging
- Rebuild indexes after bulk updates
- Use versioning for consistency

### 48. How to persist your data between program runs?
Currently reading from text files. Better approaches:
- SQLite database (embedded, ACID)
- Serialize maps to binary files
- JSON/XML for human-readable storage
- Memory-mapped files for fast loading

### 49. How can caching help here?
- **Query cache:** Store recent queries and results (LRU)
- **Result cache:** Pre-compute popular searches
- **Index cache:** Keep frequently accessed data in memory
Implementation: `unordered_map<string, string>` with LRU eviction

### 50. How would you measure and improve latency?
**Measure:** `std::chrono` timers around operations, log percentiles (p50, p95, p99)  
**Improve:**
- Profile with gprof/Valgrind
- Optimize regex patterns
- Reduce allocations
- Use faster string search (KMP)
- Add caching layer

---

## üß± System Design & Scaling

### 51. How would you design it for 10M+ queries/day?
**Architecture:**
- Load balancer (Nginx)
- Multiple app servers (horizontal scaling)
- Elasticsearch/Solr for search
- Redis cache for hot queries
- CDN for static content
- Async processing with queues
- Rate limiting and monitoring

### 52. How to store data that doesn't fit in RAM?
- **Database:** PostgreSQL/MySQL with proper indexing
- **Document stores:** MongoDB/Elasticsearch
- **Memory-mapped files:** OS handles paging
- **Distributed storage:** Cassandra/HBase for massive scale
- **Compression:** Reduce data footprint

### 53. How would you index data for faster lookup?
**Inverted Index:**
```
word ‚Üí [doc1, doc2, ...]
"array" ‚Üí [20, 22, 23, 24, ...]
"tree" ‚Üí [351, 366, 367, ...]
```
Build once, O(1) lookup per word, then intersect result sets. Used by all search engines.

### 54. How can you distribute search across multiple machines?
- **Horizontal sharding:** Split data by hash(problemID) % N
- **Document partitioning:** Each server holds subset of docs
- **Map-Reduce:** Map phase searches shards, Reduce aggregates results
- **Consensus:** Use Zookeeper/etcd for coordination
- **Replication:** Multiple copies for fault tolerance

### 55. How would you use a database for this project?
```sql
CREATE TABLE problems (
    id INT PRIMARY KEY,
    title TEXT,
    description TEXT,
    url TEXT,
    FULLTEXT INDEX(title, description)
);

SELECT * FROM problems 
WHERE MATCH(title, description) AGAINST('binary tree');
```
Benefit: ACID, full-text search, easier scaling.

### 56. How to make it thread-safe?
- Use `std::mutex` for shared data structures
- Reader-writer locks for read-heavy workloads
- Atomic operations for counters
- Lock-free data structures (boost::lockfree)
- Each thread gets own copy of data (read-only)

### 57. How would you log user queries?
```cpp
void logQuery(const string& query, const string& results) {
    ofstream log("query_log.txt", ios::app);
    log << currentTime() << "|" << query 
        << "|" << resultCount << endl;
}
```
Production: Use structured logging (JSON), log aggregation (ELK stack), analytics.

### 58. How to rank results by frequency?
Maintain query frequency counter:
```cpp
map<string, int> queryFrequency;
queryFrequency[query]++;
```
Store in database, use for:
- Auto-complete suggestions
- Trending searches
- Result re-ranking (popular results first)

### 59. How can you implement auto-suggestions?
1. Build Trie from all problem titles
2. As user types, traverse Trie
3. At current node, collect all completions
4. Rank by frequency (stored in Trie nodes)
5. Return top 10 suggestions
**Complexity:** O(prefix_length + k) for k suggestions

### 60. How to expose this as a REST API?
I already have Node.js Express API:
```javascript
POST /api/search
Body: {"query": "binary tree"}
Response: {"resultText": "...", "resultURL": "..."}
```
Add:
- GET /api/autocomplete?q=bin
- GET /api/trending
- Rate limiting middleware
- Authentication/API keys

---

## üí¨ Behavioral / Ownership

### 61. What motivated you to build this project?
I wanted to improve my DSA preparation workflow and needed hands-on experience with C++ STL, data structures, and search algorithms. Building something I'd actually use made learning more engaging.

### 62. Did you build it alone or in a team?
Built it independently from scratch - designed architecture, implemented C++ backend, added Node.js API, created web interface, and handled deployment. Fully owned the end-to-end development.

### 63. What was the hardest bug you faced?
Vector out-of-bounds error when combining search results. Filter arrays weren't initialized properly for multi-word searches. Fixed by adding bounds checking and proper initialization of the lineMatchCounts map.

### 64. How did you debug performance issues?
Added stderr logging to trace execution flow, measured file loading time, counted regex iterations, tested with various query sizes, and identified regex as the bottleneck for optimization.

### 65. What trade-offs did you make?
**Accuracy vs Speed:** Used regex (slower) over exact matching (faster) for better accuracy  
**Memory vs Computation:** Cache entire file in memory for faster repeated searches  
**Simplicity vs Features:** Started with single-word search, later added multi-word ranking

### 66. What did you learn from this project?
- STL containers (map/vector) trade-offs
- Regex performance characteristics
- File I/O optimization techniques
- Importance of error handling
- System design thinking (caching, indexing)
- How real search engines work internally

### 67. What would you improve if given more time?
- Add inverted indexing for O(1) word lookup
- Implement Trie for autocomplete
- Add fuzzy matching for typos
- Create admin panel for data management
- Add query analytics dashboard
- Implement result caching
- Write comprehensive unit tests

### 68. How did you ensure modular and clean code?
- Used OOP with separate classes (Problems, Solutions)
- Function decomposition (Life_solution, subSearch)
- Descriptive variable names
- Try-catch blocks for error handling
- Comments explaining complex logic
- Separated concerns (C++ engine, Node.js API, frontend)

### 69. How did you test correctness?
- Manual testing with various queries ("array", "tree", "stack")
- Edge cases (empty query, no matches, single word, multi-word)
- Tested with 455 actual entries
- Verified ranking logic with multi-word queries
- Checked file I/O error handling
- Web interface integration testing

### 70. What's the biggest lesson you took from this project?
**Performance vs Perfection:** Don't over-optimize early. My initial linear search works fine for 455 entries. Premature optimization would've wasted time. Build, measure, then optimize bottlenecks. Also learned that real-world systems need practical trade-offs between speed, accuracy, and maintainability.

---

## üîÅ Advanced Follow-ups

### 71. Can you replace regex with KMP or Rabin-Karp?
**Yes.** KMP has O(n+m) complexity vs regex's O(n*m).
```cpp
// KMP for exact matching
bool kmpSearch(string text, string pattern) {
    // Build LPS array, then search
    // More code but 10x faster for simple patterns
}
```
Loses pattern flexibility but gains speed. Rabin-Karp good for multiple pattern matching.

### 72. Could you use Trie for prefix search?
**Absolutely.** Trie excels at prefix queries:
```cpp
class TrieNode {
    unordered_map<char, TrieNode*> children;
    vector<int> documentIDs;
    bool isEnd;
};
```
Insert all words: O(word_length). Search prefix: O(prefix_length). Perfect for autocomplete.

### 73. How to implement inverted index in C++?
```cpp
class InvertedIndex {
    unordered_map<string, vector<int>> wordToDocuments;
    
    void addDocument(int docID, string text) {
        // Tokenize text
        for(auto word : tokens) {
            wordToDocuments[word].push_back(docID);
        }
    }
    
    vector<int> search(string word) {
        return wordToDocuments[word]; // O(1)
    }
};
```
Pre-compute once, ultra-fast searches.

### 74. How does memory fragmentation affect vectors?
Vectors use contiguous memory. When capacity exceeded, it allocates new larger block and copies all elements - O(n) operation causing fragmentation. Old block becomes free but fragmented.  
**Mitigation:** Use `reserve()` to pre-allocate if size known.

### 75. What's the difference between stack and heap allocation here?
**Stack:** Local variables (strings, ints) - fast, automatic cleanup, limited size  
**Heap:** Dynamic allocations (vector's internal array, map nodes) - slower, manual/automatic cleanup, large size  
My maps/vectors use heap internally, but wrapper objects on stack.

### 76. Can multithreading improve performance?
**Yes**, for multi-word queries:
```cpp
vector<thread> threads;
for(int i=0; i<numWords; i++) {
    threads.push_back(thread(&Solutions::Life_solution, 
                             this, words[i], i));
}
for(auto& t : threads) t.join();
```
Need mutex for `filter_search` writes. 2-4x speedup on multi-core.

### 77. How would you implement LRU cache for frequent queries?
```cpp
class LRUCache {
    list<pair<string, string>> items; // query, result
    unordered_map<string, list<iterator>> cache;
    int capacity;
    
    string get(string query) {
        if(cache.find(query) != cache.end()) {
            // Move to front (most recent)
            items.splice(items.begin(), items, cache[query]);
            return cache[query]->second;
        }
        return "";
    }
    
    void put(string query, string result) {
        if(items.size() >= capacity) {
            // Evict LRU
            cache.erase(items.back().first);
            items.pop_back();
        }
        items.push_front({query, result});
        cache[query] = items.begin();
    }
};
```

### 78. What's the complexity of inserting into a map?
**O(log n)** - must traverse tree to find position, then insert and rebalance. Rebalancing is O(log n) rotations. Overall: O(log n) for all operations (insert, find, delete).

### 79. How to avoid iterator invalidation in vectors?
**Causes:** `push_back()`, `insert()`, `erase()` when capacity exceeded  
**Solutions:**
- Use `reserve()` upfront
- Store indices instead of iterators
- Re-acquire iterators after modifications
- Use `std::list` if frequent insertions/deletions

### 80. How to handle concurrent access to shared data?
```cpp
#include <mutex>
#include <shared_mutex>

class SafeSearchEngine {
    mutable shared_mutex mtx;
    map<int, string> data;
    
    string search(int key) {
        shared_lock lock(mtx); // Multiple readers
        return data[key];
    }
    
    void update(int key, string val) {
        unique_lock lock(mtx); // Single writer
        data[key] = val;
    }
};
```
Use shared_mutex for read-heavy workloads - multiple readers, single writer.

---

## üìä Key Metrics Summary

| Metric | Value | Notes |
|--------|-------|-------|
| **Dataset Size** | 455 problems | Striver's A2Z DSA Sheet |
| **Search Time** | O(N*M*W) | N=lines, M=length, W=words |
| **Storage** | O(N) | Two maps for problems & solutions |
| **Access Time** | O(log N) | Map lookup |
| **Ranking** | O(K log K) | K=matched results |
| **Memory Usage** | ~1-2 MB | For 455 entries cached |
| **API Response** | <100ms | For typical queries |

---

## üéØ Quick Tips for Interview

1. **Start with high-level architecture** - User ‚Üí API ‚Üí C++ Engine ‚Üí Results
2. **Mention key technologies** - STL (map/vector), regex, Node.js
3. **Explain trade-offs** - Accuracy vs speed, memory vs computation
4. **Show growth mindset** - What you'd improve (indexing, Trie, caching)
5. **Connect to real systems** - Google, Elasticsearch use similar principles
6. **Be ready for follow-ups** - Threading, database, scaling
7. **Code on whiteboard** - Practice LRU cache, Trie, inverted index

---

## üìé Additional Resources
**Project Links:**
- GitHub: (Add your repo link)
- Live Demo: http://localhost:3000 (local)
- Tech Stack: C++11, STL, Node.js, Express, Regex



	‚Ä¢	High-level clarity (what the project does, why it‚Äôs useful).
	‚Ä¢	Technical depth (how you solved it, data structures, algorithms).
	‚Ä¢	Storytelling (make it engaging, not just code-walking).

Here‚Äôs how I‚Äôd restructure your script into a clean interview-ready answer:

‚∏ª

üîπ Elevator Pitch (Start with this)

‚ÄúMy project is a mini search engine CLI tool. The idea is:
	‚Ä¢	You give it a query in natural language,
	‚Ä¢	It searches through a database of problems and retrieves the most relevant ones,
	‚Ä¢	And if available, it also links the corresponding solutions.‚Äù

‚∏ª

üîπ Workflow Explanation (Layman + Technical)
	1.	Input Handling
	‚Ä¢	User enters a search query like "binary search tree".
	‚Ä¢	I break this into individual words using a stringstream.
	‚Ä¢	Words are stored in an array and mapped with their index in a map (problemStatement).
	2.	Searching in Problem File
	‚Ä¢	I have a file (Generic_Problem.txt) that contains all the problem statements.
	‚Ä¢	I load it into a map (getFileToMap) where each line has an index ‚Üí problem text.
	‚Ä¢	For each query word, I search all lines using regex word-boundary matching (\bword\b) so that "tree" doesn‚Äôt match "street".
	‚Ä¢	The results are stored in a filter_search array, where each index corresponds to the word and contains the list of line numbers it matched.
Example:
	‚Ä¢	"binary" ‚Üí lines [1, 3, 5]
	‚Ä¢	"search" ‚Üí lines [2, 3]
	‚Ä¢	"tree" ‚Üí lines [1, 3]
	3.	Combining Matches
	‚Ä¢	I count how many words from the query matched in each line ‚Üí stored in a map lineMatchCounts.
	‚Ä¢	So if line 3 matched all three words, its match count = 3.
	‚Ä¢	This gives me a relevance score.
	4.	Fetching Solutions
	‚Ä¢	I also load a second file (Generic_Solution.txt) that has URLs mapped line-wise.
	‚Ä¢	If a line in problems matches, I fetch the corresponding solution URL.
	5.	Ranking Results
	‚Ä¢	I create SearchResult objects (problem text, URL, match count).
	‚Ä¢	Then I sort results in descending order of relevance score.
Example Output:
	‚Ä¢	Match score: 3/3 ‚Üí ‚ÄúSearch in binary tree‚Äù (with solution link).
	‚Ä¢	Match score: 2/3 ‚Üí ‚ÄúBinary tree implementation‚Äù (with solution link).
	6.	No Matches Case
	‚Ä¢	If nothing matches, I append the user query to the problem file ‚Üí system becomes self-learning by recording new queries.

‚∏ª

üîπ Why This is Interesting
	‚Ä¢	It mimics how a real search engine pipeline works (tokenization ‚Üí indexing ‚Üí scoring ‚Üí retrieval).
	‚Ä¢	Used maps, vectors, regex, and sorting ‚Üí strong use of C++ STL.
	‚Ä¢	Implemented a self-updating database (new queries get stored).
	‚Ä¢	Can be extended into a full-fledged search system with inverted index or TF-IDF later.

‚∏ª

üëâ If the interviewer asks deeper:
	‚Ä¢	Talk about regex boundaries (\bword\b) to avoid partial matches.
	‚Ä¢	Mention time complexity (linear scan through file, can be improved with indexing).
	‚Ä¢	Discuss scalability improvements (like hashmaps, trie, or search libraries).
